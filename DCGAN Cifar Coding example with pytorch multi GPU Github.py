import torchvision
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torch.autograd import Variable
import time
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
import matplotlib

t1=time.time()
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Setting some hyperparameters
batchSize = 64
imageSize = 64
nz=100
nc=3
num_epochs=25
ngf=64
ndf=64

# Creating a list of transformations apply to each input image in the folder
transform = transforms.Compose([transforms.Resize(imageSize), transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),])

# Loading the dataset
dataset = datasets.CIFAR10(root = './data', download = True, transform = transform)

dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)

def weights_init(m):

    classname = m.__class__.__name__
    #get the class name of an instance by using the __name__ attribute

    if classname.find('Conv') != -1:
        #look for 'conv' from the classname string, if not present will return -1
        #if != -1 = if not equal to -1 = presnet

        m.weight.data.normal_(0.0, 0.02)
        #will set the weight for that layer

    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)

# Defining the generator
class G(nn.Module):

    def __init__(self):
        # We introduce the __init__() function that will define the architecture of the generator.
        super(G, self).__init__()
        # We inherit from the nn.Module tools and have to activate it
        #super(subClass, instance).method(args)

        self.main = nn.Sequential(

            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias = False),
            nn.BatchNorm2d(ngf*8),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf*4),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf*2),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias = False),
            nn.Tanh())

    def forward(self, input):
        output = self.main(input)
        return output

# instantiate the generator netG
netG = G()
netG=nn.DataParallel(netG)
netG.to(device)
netG.apply(weights_init)

# Defining the discriminator
class D(nn.Module):

    def __init__(self):
        super(D, self).__init__()
        self.main = nn.Sequential(

            nn.Conv2d(nc, ndf, 4, 2, 1, bias = False),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ndf*2),
            nn.LeakyReLU(0.2, inplace = True),

            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ndf*4),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ndf*8),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias = False),

            nn.Sigmoid())

    def forward(self, input):
        output = self.main(input)
        return output.view(-1)

# Creating the discriminator
netD = D()
netD=nn.DataParallel(netD)
netD.to(device)
netD.apply(weights_init)

# Training the DCGANs by updating the weight of G and D

## Initialize BCELoss function
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))

G_losses=[]
D_losses=[]
img_list=[]

fixed_noise=Variable(torch.randn(64,nz,1,1)).to(device)


for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):
        netD.zero_grad()
        real_img, _ = data
        input_real_img_tensor= Variable(real_img).to(device)
        target = Variable(torch.ones(input_real_img_tensor.size()[0])).to(device)
        output = netD(input_real_img_tensor)
        D_x= output.mean().item()

        errD_real = criterion(output, target)


        # Train D to recognize fake image generated by the generator

        noise = Variable(torch.randn(input_real_img_tensor.size()[0], nz, 1, 1)).to(device)
        fake_img_tensor = netG(noise)
        target = Variable(torch.zeros(input_real_img_tensor.size()[0])).to(device)
        output = netD(fake_img_tensor.detach())

        D_G_z1= output.mean().item()


        errD_fake = criterion(output, target)
        errD = errD_real + errD_fake
        errD.backward()
        optimizerD.step()


        # 2nd Step: Updating the weights of the neural network of the generator

        netG.zero_grad()

        target = Variable(torch.ones(input_real_img_tensor.size()[0])).to(device)
        output = netD(fake_img_tensor)
        D_G_z2= output.mean().item()

        errG = criterion(output, target)
        errG.backward()
        optimizerG.step()

        # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps
        print(f'[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}\tD(x): {D_x:.4f}\tD(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')

        G_losses.append(errG.item())
        D_losses.append(errD.item())

        if i % 100 == 0:

            vutils.save_image(real_img, '%s/real_img%03d.jpg' % ("./progress", epoch+1), normalize = True)
            fake = netG(noise) # We get our fake generated images.
            vutils.save_image(fake.data, '%s/fake_img_epoch_%03d.jpg' % ("./progress", epoch+1), normalize = True)

            fake=netG(fixed_noise).detach()
            vutils.save_image(fake.data, '%s/fake_img_version_epoch_%03d.jpg' % ("./results", epoch+1), normalize = True)

            img_list.append(vutils.make_grid(fake,padding=2,normalize=True))


#Result (3parts)
#see how D and G’s losses changed during training
#visualize G’s output on the fixed_noise batch for every epoch
#look at a batch of real data next to a batch of fake data from G

plt.figure(figsize=(10,5))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="G")
plt.plot(D_losses,label="D")
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.legend()
plt.show()

#Real Images vs. Fake Images
real_batch = next(iter(dataloader))

# Plot the real images
plt.figure(figsize=(24,24))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0], padding=2, normalize=True),(1,2,0)))

# Plot the fake images from the last epoch
plt.figure(figsize=(24,24))
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()

t2=time.time()
print(f'it take {t2-t1}s to complete')  
